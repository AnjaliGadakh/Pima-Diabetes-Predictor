{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7d58321",
   "metadata": {},
   "source": [
    "Problem Statement\n",
    "\n",
    "The objective of the dataset is to diagnostically predict whether or not a\n",
    "patient has diabetes, based on certain diagnostic measurements included in\n",
    "the dataset. All patients are females of at least 21 years of age and of Pima\n",
    "Indian heritage.\n",
    "\n",
    "The dataset consists of several medical predictor variables and one target\n",
    "variable, Outcome. Predictor variables include the number of pregnancies the\n",
    "patients have had, their BMI, insulin level, age, and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "427fabd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing required libraries\n",
    "import pandas as pd\n",
    "from sklearn import model_selection\n",
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e02ceee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the dataset, Extracting the values from the columns in the form of an array.\n",
    "# Set the random seed value as seven & number of trees as 30\n",
    "dataframe = pd.read_csv('pima-indians-diabetes.csv')\n",
    "array = dataframe.values\n",
    "X = array[:,0:8]\n",
    "Y = array[:,8]\n",
    "seed = 7\n",
    "num_trees =30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "97a4516a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7552802460697198\n"
     ]
    }
   ],
   "source": [
    "# We will build classifiers using AdaBoost & XGBoost\n",
    "# AdaBoost uses decision tree classifier as the default classifier, Pass the model within the cross validation score function to evaluate the results \n",
    "# Contruct the model by splitting the tarin test indices into 10 consecutive folds\n",
    "# Again evaluate the models such that each fold gets used once as a validation while the remaining nine folds form the training set\n",
    "kfold = model_selection.KFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "model = AdaBoostClassifier(n_estimators=num_trees)\n",
    "results = model_selection.cross_val_score(model,X,Y,cv=kfold)\n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb1169f",
   "metadata": {},
   "source": [
    "AdaBoost gives an accuracy of 75%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f9ec3a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7382433356117566\n"
     ]
    }
   ],
   "source": [
    "# Simlarly we apply XGBoost algorithm, Importing respective modules, namely SVM & XGBClassifier\n",
    "# Initialize XGBClassifier under the name clf\n",
    "from sklearn import svm\n",
    "from xgboost import XGBClassifier\n",
    "clf = XGBClassifier()\n",
    "\n",
    "seed = 7\n",
    "num_trees = 30\n",
    "\n",
    "kfold = model_selection.KFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "model = XGBClassifier(n_estimators=num_trees)\n",
    "results = model_selection.cross_val_score(model,X,Y,cv=kfold)\n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b508b5",
   "metadata": {},
   "source": [
    "Again the accuracy is around 75%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
